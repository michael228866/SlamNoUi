#include "marker.h"
#include "markerdetector.h"
#include "cameraparameters.h"
#include <opencv2/highgui.hpp>
#include <opencv2/imgcodecs.hpp>
#include <opencv2/core/core.hpp>
#include <opencv2/calib3d.hpp>
#include <opencv2/video/tracking.hpp>
#include <Eigen/Dense>
#include <Eigen/Geometry>
#include <iostream>
#include <fstream>
#include <map>
#include <ctime>
#include <iomanip>
#include <ixwebsocket/IXWebSocket.h>

ix::WebSocket websocket;


using namespace std;
using namespace aruco;
using namespace Eigen;

struct MarkerPose {
    int id;
    cv::Vec3d tvec;
    cv::Vec3d rvec;
};

// class KalmanFilter3D {
// private:
//     cv::KalmanFilter kf;
//     cv::Mat state;
//     cv::Mat meas;
//     double dt;

// public:
//     KalmanFilter3D(double dt = 1.0 / 30.0) : dt(dt) {
//         kf.init(6, 3, 0, CV_64F);
//         state = cv::Mat::zeros(6, 1, CV_64F);
//         meas = cv::Mat::zeros(3, 1, CV_64F);

//         kf.transitionMatrix = (cv::Mat_<double>(6, 6) <<
//             1, 0, 0, dt, 0, 0,
//             0, 1, 0, 0, dt, 0,
//             0, 0, 1, 0, 0, dt,
//             0, 0, 0, 1, 0, 0,
//             0, 0, 0, 0, 1, 0,
//             0, 0, 0, 0, 0, 1);

//         kf.measurementMatrix = cv::Mat::zeros(3, 6, CV_64F);
//         for (int i = 0; i < 3; ++i)
//             kf.measurementMatrix.at<double>(i, i) = 1.0;

//         cv::setIdentity(kf.processNoiseCov, cv::Scalar::all(1e-3));
//         cv::setIdentity(kf.measurementNoiseCov, cv::Scalar::all(1e-1));
//         cv::setIdentity(kf.errorCovPost, cv::Scalar::all(0.1));
//     }

//     cv::Vec3d update(const cv::Vec3d& measurement) {
//         kf.predict();
//         for (int i = 0; i < 3; ++i)
//             meas.at<double>(i) = measurement[i];
//         kf.correct(meas);
//         for (int i = 0; i < 3; ++i)
//             state.at<double>(i) = kf.statePost.at<double>(i);
//         return cv::Vec3d(state.at<double>(0), state.at<double>(1), state.at<double>(2));
//     }

//     cv::Vec3d predictOnly() {
//     kf.predict();
//     for (int i = 0; i < 3; ++i)
//         state.at<double>(i) = kf.statePre.at<double>(i);
//     return cv::Vec3d(state.at<double>(0), state.at<double>(1), state.at<double>(2));
//     }
// };

bool loadCameraParams(const string& filename, CameraParameters& camParams) {
    try {
        camParams.readFromXMLFile(filename);
        return camParams.isValid();
    } catch (...) {
        return false;
    }
}

map<int, MarkerPose> loadMap(const string& filename, float markerSize) {
    map<int, MarkerPose> poses;
    cv::FileStorage fs(filename, cv::FileStorage::READ);
    if (!fs.isOpened()) {
        cerr << "âŒ ç„¡æ³•é–‹å•Ÿåœ°åœ–æª”æ¡ˆï¼š" << filename << endl;
        return poses;
    }

    cv::FileNode markers = fs["aruco_bc_markers"];
    if (markers.empty() || !markers.isSeq()) {
        cerr << "âŒ åœ°åœ–æ ¼å¼éŒ¯èª¤ï¼šç¼ºå°‘ 'aruco_bc_markers'" << endl;
        return poses;
    }

    float half = markerSize / 2.0f;
    vector<Vector3d> objPts = {
        {-half,  half, 0},
        { half,  half, 0},
        { half, -half, 0},
        {-half, -half, 0}
    };

    for (const auto& m : markers) {
        int id = (int)m["id"];
        cv::FileNode cornersNode = m["corners"];
        if (cornersNode.size() != 4) continue;

        vector<Vector3d> worldPts;
        for (int i = 0; i < 4; ++i) {
            cv::Vec3f pt;
            cornersNode[i] >> pt;
            worldPts.emplace_back(pt[0], pt[1], pt[2]);
        }

        // è¨ˆç®—ä¸­å¿ƒ
        Vector3d center_obj = Vector3d::Zero();
        Vector3d center_world = Vector3d::Zero();
        for (int i = 0; i < 4; ++i) {
            center_obj += objPts[i];
            center_world += worldPts[i];
        }
        center_obj /= 4.0;
        center_world /= 4.0;

        // å»ä¸­å¿ƒåŒ–
        MatrixXd X(3, 4), Y(3, 4);
        for (int i = 0; i < 4; ++i) {
            X.col(i) = objPts[i] - center_obj;
            Y.col(i) = worldPts[i] - center_world;
        }

        // SVD æ±‚æ—‹è½‰
        Matrix3d H = X * Y.transpose();
        JacobiSVD<Matrix3d> svd(H, ComputeFullU | ComputeFullV);
        Matrix3d R = svd.matrixV() * svd.matrixU().transpose();

        // æª¢æŸ¥æ˜¯å¦ç¿»è½‰ï¼ˆé¿å…åå°„ï¼‰
        if (R.determinant() < 0) {
            Matrix3d V = svd.matrixV();
            V.col(2) *= -1;
            R = V * svd.matrixU().transpose();
        }

        Vector3d t = center_world - R * center_obj;

        // å„²å­˜çµæœ
        MarkerPose mp;
        mp.id = id;

        // è½‰ç‚º OpenCV Vec3d
        cv::Mat R_cv = (cv::Mat_<double>(3, 3) <<
            R(0, 0), R(0, 1), R(0, 2),
            R(1, 0), R(1, 1), R(1, 2),
            R(2, 0), R(2, 1), R(2, 2));
        cv::Rodrigues(R_cv, mp.rvec);
        mp.tvec = cv::Vec3d(t(0), t(1), t(2));

        poses[mp.id] = mp;
    }

    return poses;
}

const int SLIDING_WINDOW = 5;
std::deque<cv::Vec3d> recent_positions;

//å¯ä¿¡åº¦
double calculateConfidence(double reprojection_error, double angle_deg, double distance,float markerSize) {
    // è¨­å®šæ¬Šé‡èˆ‡é™åˆ¶
    const double max_error = 4.0;      // èª¤å·®ä¸Šé™
    const double max_angle = 60.0;     // è§’åº¦ä¸Šé™ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    double scale_factor = 12.0;

    const double max_distance = markerSize*scale_factor;   // è·é›¢ä¸Šé™ï¼ˆä¾å ´æ™¯èª¿æ•´ï¼‰

    // å„é …è©•åˆ† (0~1)ï¼Œè¶Šæ¥è¿‘ 1 è¶Šå¥½
    double score_err = std::max(0.0, 1.0 - (reprojection_error / max_error));
    double score_angle = std::max(0.0, 1.0 - (angle_deg / max_angle));
    double score_dist = std::max(0.0, 1.0 - (distance / max_distance));

    // åŠ æ¬Šå¹³å‡ (å¯èª¿æ•´æ¯”é‡)
    double confidence = (score_err * 0.4) + (score_angle * 0.4) + (score_dist * 0.2);
    return confidence;
}


int main(int argc, char** argv) {

   cout << "ğŸš€ ç¨‹å¼å•Ÿå‹•" << endl;

    if (argc < 4) {
        cout << "â— åƒæ•¸ä¸è¶³" << endl;
        return -1;
    }

    cout << "ğŸ“ è¼‰å…¥åƒæ•¸..." << endl;
    string mapPath = argv[1];
    string camPath = argv[2];
    float markerSize = stof(argv[3]);

    cout << "ğŸ“· å˜—è©¦è¼‰å…¥ç›¸æ©Ÿåƒæ•¸..." << endl;
    CameraParameters camParams;
    if (!loadCameraParams(camPath, camParams)) {
        cerr << "âŒ ç›¸æ©Ÿåƒæ•¸è®€å–å¤±æ•—ï¼š" << camPath << endl;
        return -1;
    }
    cout << "âœ… ç›¸æ©Ÿåƒæ•¸è®€å–æˆåŠŸ" << endl;

    cout << "ğŸ—ºï¸ å˜—è©¦è¼‰å…¥ marker map..." << endl;
    auto map = loadMap(mapPath, markerSize);
    if (map.empty()) {
        cerr << "âŒ åœ°åœ–è®€å–å¤±æ•—ï¼š" << mapPath << endl;
        return -1;
    }
    cout << "âœ… åœ°åœ–è¼‰å…¥å®Œæˆï¼Œå…±æœ‰ " << map.size() << " å€‹ marker" << endl;

    cout << "ğŸ“· å˜—è©¦é–‹å•Ÿæ”å½±æ©Ÿ..." << endl;
    cv::VideoCapture cap("libcamerasrc ! videoconvert ! appsink", cv::CAP_GSTREAMER);
    if (!cap.isOpened()) {
        cerr << "âŒ æ”å½±æ©Ÿæ‰“ä¸é–‹ï¼ˆGStreamer pipelineï¼‰" << endl;
        return -1;
    }
    cout << "âœ… æ”å½±æ©Ÿé–‹å•ŸæˆåŠŸ" << endl;


    // è¨­å®š WebSocket URL
    websocket.setUrl("ws://192.168.9.96:5000?type=vr_headset&clientId=vr001");

    // è¨­å®šè¨Šæ¯æ¥æ”¶ callbackï¼ˆé€™æ˜¯ä½ éœ€è¦çš„æœ€åŸºæœ¬åŠŸèƒ½ï¼‰
    websocket.setOnMessageCallback([](const ix::WebSocketMessagePtr& msg) {
        if (msg->type == ix::WebSocketMessageType::Message) {
            std::cout << "ğŸ“© æ”¶åˆ°è¨Šæ¯ï¼š" << msg->str << std::endl;
        } else if (msg->type == ix::WebSocketMessageType::Open) {
            std::cout << "âœ… WebSocket å·²é€£ç·š" << std::endl;
        } else if (msg->type == ix::WebSocketMessageType::Error) {
            std::cerr << "âŒ WebSocket éŒ¯èª¤ï¼š" << msg->errorInfo.reason << std::endl;
        } else if (msg->type == ix::WebSocketMessageType::Close) {
            std::cout << "âŒ WebSocket é—œé–‰ï¼ŒåŸå› : " << msg->closeInfo.reason << std::endl;
        }
    });

    websocket.start();

    // double fps = cap.get(cv::CAP_PROP_FPS);
    // KalmanFilter3D kalman_filter(1.0 / fps );

    MarkerDetector detector;
    detector.setDictionary("ARUCO_MIP_36h12");
    detector.getParameters().setCornerRefinementMethod(aruco::CornerRefinementMethod::CORNER_SUBPIX);

    cv::Mat frame;
    while (true) {
        cap >> frame;
        if (frame.empty()) break;

        vector<Marker> detectedMarkers;
        detector.detect(frame, detectedMarkers, camParams, markerSize);

        vector<cv::Mat> poses;
        
        for (const auto& marker : detectedMarkers) {
            cout << "\033[1;34mâœ” åµæ¸¬åˆ° Marker ID:\033[0m " << marker.id << endl;

            auto it = map.find(marker.id);
            if (it == map.end()) {
                cout << "âš ï¸ Marker ID " << marker.id << " ä¸åœ¨åœ°åœ–ä¸­ï¼Œç•¥éã€‚\n";
                continue;
            }

            cv::Mat rvec_marker, tvec_marker;
            cv::Rodrigues(cv::Mat(it->second.rvec), rvec_marker);
            tvec_marker = cv::Mat(it->second.tvec).clone();

            cv::Mat rvec_relative = marker.Rvec.clone();
            cv::Mat tvec_relative = marker.Tvec.clone();

            cv::Mat R_marker_to_cam;
            cv::Rodrigues(rvec_relative, R_marker_to_cam);

            cv::Mat T_marker_to_cam = cv::Mat::eye(4, 4, CV_64F);
            R_marker_to_cam.copyTo(T_marker_to_cam(cv::Rect(0, 0, 3, 3)));
            T_marker_to_cam.at<double>(0, 3) = tvec_relative.at<float>(0);
            T_marker_to_cam.at<double>(1, 3) = tvec_relative.at<float>(1);
            T_marker_to_cam.at<double>(2, 3) = tvec_relative.at<float>(2);

            cv::Mat R_map_marker;
            cv::Rodrigues(cv::Mat(it->second.rvec), R_map_marker);
            cv::Mat T_map_marker = cv::Mat::eye(4, 4, CV_64F);
            R_map_marker.copyTo(T_map_marker(cv::Rect(0, 0, 3, 3)));
            T_map_marker.at<double>(0, 3) = tvec_marker.at<double>(0);
            T_map_marker.at<double>(1, 3) = tvec_marker.at<double>(1);
            T_map_marker.at<double>(2, 3) = tvec_marker.at<double>(2);

            cv::Mat T_map_to_cam = T_map_marker * T_marker_to_cam;
            cv::Mat cam_pos = T_map_to_cam(cv::Rect(3, 0, 1, 3)).clone();
            cv::Mat marker_pos = cv::Mat(it->second.tvec).clone();
            cv::Mat dir_to_marker = marker_pos - cam_pos;
            dir_to_marker /= cv::norm(dir_to_marker);

            cv::Mat cam_z = T_map_to_cam(cv::Rect(2, 0, 1, 3)).clone();
            cam_z /= cv::norm(cam_z);

            double dot_product = cam_z.dot(dir_to_marker);
            dot_product = std::max(-1.0, std::min(1.0, dot_product));
            double angle_rad = acos(dot_product);
            double angle_deg = angle_rad * 180.0 / CV_PI;

            if (angle_deg > 50) {
                cout << "è§’åº¦" << angle_deg << " è¶…é60åº¦æ‰€ä»¥ï¼Œç•¥éã€‚\n";
                continue;
            }
           
            vector<cv::Point2f> reprojected;
            cv::projectPoints(marker.get3DPoints(markerSize), marker.Rvec, marker.Tvec,
                            camParams.CameraMatrix, camParams.Distorsion, reprojected);

            double error = 0.0;
            for (size_t i = 0; i < 4; ++i) {
                error += cv::norm(marker[i] - reprojected[i]);
            }
            if (error > 4.0) {
                cerr << "âŒ æ¨™è¨˜ " << marker.id << " é‡æŠ•å½±èª¤å·®éå¤§: " << error << endl;
                continue;
            } else {
                cout << "âœ… æ¨™è¨˜ " << marker.id << " é‡æŠ•å½±èª¤å·®: " << error << endl;
            }

            double distance = cv::norm(marker.Tvec);
            double confidence = calculateConfidence(error, angle_deg, distance,markerSize);
            cout << "ğŸ” ä¿¡å¿ƒå€¼ (Confidence): " << confidence << endl;

            // å¯é¸ï¼šåŠ å…¥ä¿¡å¿ƒå€¼éä½å‰‡è·³é
            if (confidence < 0.5) {
                cout << "âš ï¸ å¯ä¿¡åº¦å¤ªä½ (" << confidence << ")ï¼Œç•¥éæ­¤ markerã€‚\n";
                continue;
            }


            cout << "Estimated camera pose (map -> camera):\n" << T_map_to_cam << endl;
            poses.push_back(T_map_to_cam);
        }



        if (!poses.empty()) {
            cv::Vec3d avg_t(0, 0, 0);
            vector<Quaterniond> quats;

            for (const auto& T : poses) {
                avg_t += cv::Vec3d(T.at<double>(0, 3), T.at<double>(1, 3), T.at<double>(2, 3));

                Matrix3d R;
                for (int i = 0; i < 3; ++i)
                    for (int j = 0; j < 3; ++j)
                        R(i, j) = T.at<double>(i, j);

                Quaterniond q(R);
                if (q.w() < 0) q.coeffs() *= -1;
                quats.push_back(q);
            }
            avg_t *= (1.0 / poses.size());

            // â¤ åŠ å…¥é€²æ»‘å‹•è¦–çª—
            recent_positions.push_back(avg_t);
            if (recent_positions.size() > SLIDING_WINDOW)
                recent_positions.pop_front();

            // â¤ è¨ˆç®—æ»‘å‹•å¹³å‡
            cv::Vec3d smooth_t(0, 0, 0);
            int N = recent_positions.size();
            double total_weight = 0.0;

            for (int i = 0; i < N; ++i) {
                double weight = (i + 1);  // æ¬Šé‡ç·šæ€§æˆé•·ï¼š1, 2, ..., N
                total_weight += weight;
                smooth_t += recent_positions[i] * weight;
            }
            smooth_t *= (1.0 / total_weight);

            // â¤ å†é€² Kalman æ¿¾æ³¢
            // cv::Vec3d filtered_t = kalman_filter.update(smooth_t);

            cv::Vec3d filtered_t = smooth_t;

            
            Quaterniond q_avg(0, 0, 0, 0);
            for (const auto& q : quats)
                q_avg.coeffs() += q.coeffs();
            q_avg.normalize();

            Matrix3d R_avg = q_avg.toRotationMatrix();

            cv::Mat T_avg = cv::Mat::eye(4, 4, CV_64F);
            for (int i = 0; i < 3; ++i)
                for (int j = 0; j < 3; ++j)
                    T_avg.at<double>(i, j) = R_avg(i, j);
            T_avg.at<double>(0, 3) = filtered_t[0];
            T_avg.at<double>(1, 3) = filtered_t[1];
            T_avg.at<double>(2, 3) = filtered_t[2];

            // æå–ç›¸æ©Ÿå§¿æ…‹ä¸‰è»¸æ–¹å‘ï¼ˆä¸–ç•Œåæ¨™ä¸­ï¼‰
            cv::Vec3d x_axis(T_avg.at<double>(0, 0), T_avg.at<double>(1, 0), T_avg.at<double>(2, 0));
            cv::Vec3d y_axis(T_avg.at<double>(0, 1), T_avg.at<double>(1, 1), T_avg.at<double>(2, 1));
            cv::Vec3d z_axis(T_avg.at<double>(0, 2), T_avg.at<double>(1, 2), T_avg.at<double>(2, 2));

            x_axis /= cv::norm(x_axis);
            y_axis /= cv::norm(y_axis);
            z_axis /= cv::norm(z_axis);

            cout << "ğŸ§­ X è»¸æ–¹å‘ (å³): " << x_axis << endl;
            cout << "ğŸ§­ Y è»¸æ–¹å‘ (ä¸Š): " << y_axis << endl;
            cout << "ğŸ§­ Z è»¸æ–¹å‘ (å‰): " << z_axis << endl;


            cout << "\033[1;32må¹³å‡ç›¸æ©Ÿä½ç½®:\033[0m " << filtered_t << endl;
            cout << "å¹³å‡ç›¸æ©Ÿå§¿æ…‹çŸ©é™£ (map -> camera):\n" << T_avg << endl;


            std::stringstream json;
            json << std::fixed << std::setprecision(6);
            json << R"({"type": "transform_update", "headsetId": "1", "pos": [)"
                << filtered_t[0] << ", " << filtered_t[1] << ", " << filtered_t[2]
                << R"(], "orient": [)"
                << z_axis[0] << ", " << z_axis[1] << ", " << z_axis[2] << "]}";

            std::string json_str = json.str();
            std::cout << "ğŸ“¤ Sent JSON: " << json_str << std::endl;

            websocket.send(json_str);
            
        }else {
            // æ²’æœ‰åµæ¸¬åˆ° markerï¼Œä¹Ÿåš Kalman é æ¸¬
            // cv::Vec3d filtered_t = kalman_filter.predictOnly();
        }
    }

    return 0;


}